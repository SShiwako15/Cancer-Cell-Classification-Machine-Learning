{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a78fecef-b8b2-4cf1-9244-72325e69e5b8",
   "metadata": {},
   "source": [
    "For this Project we will be using Scikit-Learn and utilizing the Wisconsin Breast Cancer(Diagnostic) dataset. Since it is a database that is already available on scikit-learn we can import it directly from the Library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5935bfcf-f348-4a2a-9167-06ba85a12903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1a0feb-9dc4-4a7b-acdc-28f75a081352",
   "metadata": {},
   "source": [
    "Load the required data set and organize the data into difference appropriately named variables, and observe the Number of data and features available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9446d8ed-a62d-4af0-a0cf-8f3acacbf4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "['malignant' 'benign']\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "\n",
    "#Organize our data into Target, Target Names, Features, and Feature Names\n",
    "target_names = data['target_names']\n",
    "targets = data['target']\n",
    "features = data['data']\n",
    "feature_names = data['feature_names']\n",
    "\n",
    "print(features.shape)\n",
    "print(target_names)\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efd023e-c9d0-40d3-acbc-6f1690a88698",
   "metadata": {},
   "source": [
    "We have a decent number of observations to work with, and can select an Algorithm accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4758d12b-1fd2-422e-aa8f-5ef0472f9722",
   "metadata": {},
   "source": [
    "Upon examination of the organized data, we are able to see the targets and the features we are given to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84845d5b-c617-46f8-a391-7ad831e81a48",
   "metadata": {},
   "source": [
    "Let us use KNN Algorithm and Naive Bayes Algorithm as classification algorithm. We can select one of the two based on which algorithm is able to provide higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0900f2a5-589f-48eb-982c-69dd1aaf8ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy for KNN: 0.9384722869119703\n",
      "Mean Accuracy for GNB: 0.9384257102934328\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "accuracy_sum = 0\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    target_train, target_test = targets[train_index], targets[test_index]\n",
    "\n",
    "    knn.fit(features_train, target_train)\n",
    "    predictions = knn.predict(features_test)\n",
    "    accuracy = accuracy_score(target_test, predictions)\n",
    "    accuracy_sum = accuracy_sum + accuracy\n",
    "print(\"Mean Accuracy for KNN:\",accuracy_sum/5.0)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=10)\n",
    "accuracy_sum = 0\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    target_train, target_test = targets[train_index], targets[test_index]\n",
    "\n",
    "    gnb.fit(features_train, target_train)\n",
    "    predictions = gnb.predict(features_test)\n",
    "    accuracy = accuracy_score(target_test, predictions)\n",
    "    accuracy_sum = accuracy_sum + accuracy\n",
    "print(\"Mean Accuracy for GNB:\",accuracy_sum/5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c634c388-60d6-4181-86bf-1ea7ea9a2977",
   "metadata": {},
   "source": [
    "So, we find out that this Machine Learning Classifier when based on K-Nearest Neighborhood algorithm gives an Accuracy of 93.847%, while the Classifier based on Gaussian Naive Bayes gives an Accuracy of 93.842%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
